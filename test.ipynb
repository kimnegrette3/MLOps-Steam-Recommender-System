{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\octav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\octav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from deep_translator import GoogleTranslator # traductor\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # analyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# descarga necesaria para correr el analizador de sentimiento\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Cargar el archivo CSV con las reseñas\n",
    "df_exp_revs = pd.read_csv('./datasets/aus_user_revs.csv')\n",
    "\n",
    "# Cargar lista de stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Inicializar SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoticons(text2):\n",
    "    # Patrón de expresión regular para detectar emoticonos\n",
    "    emoticon_pattern = re.compile(\"[\"\n",
    "                                 u\"\\U0001F600-\\U0001F64F\"  # Emoticonos de caritas\n",
    "                                 u\"\\U0001F300-\\U0001F5FF\"  # Símbolos y pictogramas\n",
    "                                 u\"\\U0001F680-\\U0001F6FF\"  # Símbolos de transporte y tecnología\n",
    "                                 u\"\\U0001F700-\\U0001F77F\"  # Símbolos de alquimia\n",
    "                                 u\"\\U0001F780-\\U0001F7FF\"  # Símbolos de cartas y dominó\n",
    "                                 u\"\\U0001F800-\\U0001F8FF\"  # Símbolos suplementarios de cartas\n",
    "                                 u\"\\U0001F900-\\U0001F9FF\"  # Símbolos suplementarios y de uso común\n",
    "                                 u\"\\U0001FA00-\\U0001FA6F\"  # Símbolos suplementarios de uso común\n",
    "                                 u\"\\U0001FA70-\\U0001FAFF\"  # Símbolos suplementarios de uso común\n",
    "                                 u\"\\U0001F200-\\U0001F251\"  # Símbolos de la rueda del dharma\n",
    "                                 \"]+\", flags=re.UNICODE)\n",
    "    return emoticon_pattern.sub(r'', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_value(text):\n",
    "    if isinstance(text, str):\n",
    "        text = remove_emoticons(text)\n",
    "        # Tokenizar y eliminar stop words\n",
    "        words = nltk.word_tokenize(text)\n",
    "        words = [word for word in words if word.lower() not in stop_words]\n",
    "        cleaned_text = ' '.join(words)\n",
    "\n",
    "        # Realizar análisis de sentimiento\n",
    "        sentiment_score = sia.polarity_scores(cleaned_text)\n",
    "        compound_score = sentiment_score['compound']\n",
    "\n",
    "        if compound_score < -0.1:  # Si el sentimiento es negativo\n",
    "            return 0\n",
    "        elif compound_score > 0.1:  # Si el sentimiento es positivo\n",
    "            return 2\n",
    "        else:  # Si el sentimiento es neutro\n",
    "            return 1\n",
    "        \n",
    "    else:\n",
    "        return None  # Valor nulo si no es un texto\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar análisis de sentimiento y asignar valores\n",
    "# df_exp_revs['sentiment_analysis'] = df_exp_revs['review'].apply(get_sentiment_value)\n",
    "df_exp_revs['sentiment_analysis'] = df_exp_revs['review'].apply(get_sentiment_value)\n",
    "\n",
    "# Guardar el DataFrame con la nueva columna en un nuevo archivo CSV\n",
    "df_exp_revs.to_csv('./datasets/aus_user_revs_with_sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>wuuuuu i got this ♥♥♥♥♥♥♥ game free see ya in ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29846</th>\n",
       "      <td>I got this with the bundle of Worms (tm) games...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>You get to play as Ron Pearlman.What more do y...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6436</th>\n",
       "      <td>Alright, i'll be completely honest here.i had ...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34057</th>\n",
       "      <td>I've only just walked around and run through s...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment_analysis\n",
       "4167   wuuuuu i got this ♥♥♥♥♥♥♥ game free see ya in ...                 2.0\n",
       "29846  I got this with the bundle of Worms (tm) games...                 0.0\n",
       "1896   You get to play as Ron Pearlman.What more do y...                 2.0\n",
       "6436   Alright, i'll be completely honest here.i had ...                 2.0\n",
       "34057  I've only just walked around and run through s...                 2.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_revs[['review','sentiment_analysis']].sample(n=5,random_state=44574849)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I got this with the bundle of Worms (tm) games a while back - after a bit of research it turns out it's made by Ubisoft for multiple platforms back in the early 2000's (Don't believe the time on record that steam provides, as I managed to find an original copy for the Gamecube recently. I regret that).This really shows - many Ubisoft games that used lisenced franchises like Disney or other big names at the time often had significanly lower quality in-comparison to their own IP's while also putting a 'spin' on whatever popular game mechanics were being used for these 'outsourced' titles (I.e. a Donald Duck themed Crash Bandicoot with a modified health system ran poorly and is easily beaten by the 3D Rayman titles).Ubisoft's 'spin' this time is the momentum of your movement being mixed with Worms (tm) weapons to create a clunky puzzle game that has the main difficulty being setting up your 'answer' to the challenges that it provides instead of the actual puzzles themselves.Also, Worms games don't even allow users to move when aiming - it feels counter-intuitive to the original franchise too.Not reccommended unless the clunky-2000's style appeals to your rose-tinted nostalgia glasses.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp_revs['review'].loc[29846]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        transcript                              hello\n",
      "0                       hola mundo                        Hello World\n",
      "1  vives la vida como un rockstar?  Do you live life like a rockstar?\n",
      "2                    color del mar                   color of the sea\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([(\"hola mundo\",\"nan\"),\n",
    "                   (\"vives la vida como un rockstar?\",\"nan\"),\n",
    "                   (\"color del mar\",\"nan\")],\n",
    "                  columns=(\"transcript\",'hello'))\n",
    "\n",
    "# creamos el objeto que nos permitirá hacer la traducción\n",
    "translator = GoogleTranslator(source=\"es\", target=\"en\")\n",
    "\n",
    "# Usamos el método apply de las series en pandas para aplicar a cada valor de la serie una función.\n",
    "# Esta función será el método translate del objeto translator.\n",
    "# Luego, reemplazamos la columna original por la modificada\n",
    "df['hello'] = df['transcript'].apply(translator.translate)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "import pandas as pd\n",
    "\n",
    "# Función para traducir fragmentos de texto\n",
    "def translate_text(text, translator):\n",
    "    max_length = 5000\n",
    "    chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "    translated_chunks = [translator.translate(chunk) for chunk in chunks]\n",
    "    return ''.join(translated_chunks)\n",
    "\n",
    "# Cargar el archivo CSV con las reseñas\n",
    "df = pd.read_csv('./datasets/aus_user_revs.csv')\n",
    "\n",
    "# Creamos el objeto que nos permitirá hacer la traducción\n",
    "translator = GoogleTranslator(source=\"es\", target=\"en\")\n",
    "\n",
    "# Aplicar la traducción a las reseñas\n",
    "df['transcript'] = df['review'].apply(lambda x: translate_text(x, translator) \n",
    "                                      if isinstance(x, str) and x.strip() else 1)\n",
    "\n",
    "\n",
    "# Guardar el DataFrame con las traducciones\n",
    "df.to_csv('./datasets/aus_user_revs_translated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
